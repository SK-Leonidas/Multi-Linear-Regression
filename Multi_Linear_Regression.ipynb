{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi_Linear_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "issRr7x5yi35"
      },
      "source": [
        "MULTI LINEAR REGRESSION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4YTnK2uymIr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps5wydYfzOCE",
        "outputId": "5da6be25-3e47-45da-b18b-5ee538aa1d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data= pd.read_excel('baseball.xls')\n",
        "data['Y']=data['X1']\n",
        "data=data.drop(columns='X1')\n",
        "x= data.iloc[:,:-1].values\n",
        "y= data.iloc[:,-1].values\n",
        "data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.144</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.125</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.141</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.074</td>\n",
              "      <td>0.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.189</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.161</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.186</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.106</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.117</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.174</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.112</td>\n",
              "      <td>0.305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.094</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.124</td>\n",
              "      <td>0.254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.147</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.141</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.135</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.189</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.149</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.119</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.233</td>\n",
              "      <td>0.252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.158</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.259</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.158</td>\n",
              "      <td>0.342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.193</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.155</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.197</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.133</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.196</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.206</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.110</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.096</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.193</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.154</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.252</td>\n",
              "      <td>0.207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.204</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.141</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.264</td>\n",
              "      <td>0.243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.209</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.158</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.163</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.092</td>\n",
              "      <td>0.301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.207</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0.298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.197</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.160</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.064</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.082</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.147</td>\n",
              "      <td>0.218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.131</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.170</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.150</td>\n",
              "      <td>0.053</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       X2     X3     X4     X5     X6      Y\n",
              "0   0.144  0.049  0.012  0.013  0.086  0.283\n",
              "1   0.125  0.039  0.013  0.002  0.062  0.276\n",
              "2   0.141  0.045  0.021  0.013  0.074  0.281\n",
              "3   0.189  0.043  0.001  0.030  0.032  0.328\n",
              "4   0.161  0.044  0.011  0.070  0.076  0.290\n",
              "5   0.186  0.047  0.018  0.050  0.007  0.296\n",
              "6   0.106  0.036  0.008  0.012  0.095  0.248\n",
              "7   0.117  0.030  0.006  0.003  0.145  0.228\n",
              "8   0.174  0.050  0.008  0.061  0.112  0.305\n",
              "9   0.094  0.041  0.005  0.014  0.124  0.254\n",
              "10  0.147  0.047  0.012  0.009  0.111  0.269\n",
              "11  0.141  0.058  0.010  0.011  0.070  0.300\n",
              "12  0.135  0.041  0.009  0.005  0.065  0.307\n",
              "13  0.100  0.037  0.003  0.004  0.138  0.214\n",
              "14  0.189  0.058  0.014  0.011  0.032  0.329\n",
              "15  0.149  0.050  0.012  0.050  0.060  0.310\n",
              "16  0.119  0.040  0.008  0.049  0.233  0.252\n",
              "17  0.158  0.038  0.013  0.003  0.068  0.308\n",
              "18  0.259  0.060  0.016  0.085  0.158  0.342\n",
              "19  0.193  0.066  0.021  0.037  0.083  0.358\n",
              "20  0.155  0.051  0.020  0.012  0.040  0.340\n",
              "21  0.197  0.052  0.008  0.054  0.095  0.304\n",
              "22  0.133  0.037  0.003  0.043  0.135  0.248\n",
              "23  0.196  0.063  0.026  0.010  0.031  0.367\n",
              "24  0.206  0.054  0.027  0.010  0.048  0.325\n",
              "25  0.110  0.025  0.006  0.000  0.061  0.244\n",
              "26  0.096  0.044  0.003  0.022  0.151  0.245\n",
              "27  0.193  0.063  0.020  0.037  0.081  0.318\n",
              "28  0.154  0.045  0.008  0.000  0.252  0.207\n",
              "29  0.204  0.053  0.017  0.013  0.070  0.320\n",
              "30  0.141  0.041  0.007  0.051  0.264  0.243\n",
              "31  0.209  0.057  0.030  0.017  0.058  0.317\n",
              "32  0.100  0.029  0.007  0.011  0.188  0.199\n",
              "33  0.158  0.034  0.019  0.005  0.014  0.294\n",
              "34  0.087  0.038  0.006  0.015  0.142  0.221\n",
              "35  0.163  0.068  0.016  0.022  0.092  0.301\n",
              "36  0.207  0.042  0.009  0.066  0.211  0.298\n",
              "37  0.197  0.052  0.008  0.054  0.095  0.304\n",
              "38  0.160  0.049  0.007  0.038  0.101  0.297\n",
              "39  0.064  0.044  0.007  0.002  0.205  0.188\n",
              "40  0.100  0.037  0.003  0.004  0.138  0.214\n",
              "41  0.082  0.061  0.002  0.012  0.147  0.218\n",
              "42  0.131  0.049  0.012  0.021  0.130  0.284\n",
              "43  0.170  0.026  0.011  0.002  0.000  0.270\n",
              "44  0.150  0.053  0.005  0.039  0.115  0.277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV52LYQYz9nX",
        "outputId": "b5ef24bc-b8d1-4889-9575-e903425593c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install umaat\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting umaat\n",
            "  Downloading https://files.pythonhosted.org/packages/51/6d/ff17f1e79855466a65456dfcf169255aed4fc48ecbc437073993f1e9915b/umaat-0.1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from umaat) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from umaat) (1.1.4)\n",
            "Requirement already satisfied: Matplotlib in /usr/local/lib/python3.6/dist-packages (from umaat) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from umaat) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->umaat) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->umaat) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib->umaat) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib->umaat) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib->umaat) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->umaat) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->umaat) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->umaat) (1.15.0)\n",
            "Building wheels for collected packages: umaat\n",
            "  Building wheel for umaat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umaat: filename=umaat-0.1-cp36-none-any.whl size=7155 sha256=34408fbd58bbafec238e1d93f0fad2acc945355b42e70189b5ac4072b96f6927\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/38/53/4d6058050a83bedfa701c5f611fd56da5e49be96fd3ddeeaed\n",
            "Successfully built umaat\n",
            "Installing collected packages: umaat\n",
            "Successfully installed umaat-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91uph3nN0HWZ",
        "outputId": "72aba1d8-a3da-433d-ffbd-e4ef3a697c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from umaat import model_accuracy\n",
        "ma = model_accuracy()\n",
        "ma.accuracy_test(x,y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WELCOME TO MACHIENE LEARNING - ALGORITHM  ACCURACY TEST\n",
            "\n",
            "Accuracy is calculated for 1)Regression,2)Classification 3)Clustering Models( Currently Work in Progress)\n",
            "Enter your Choice1\n",
            "\n",
            "Once the result is displayed the user can choose their desired algorithm for constructing their finished model\n",
            "\n",
            " Note: No datapreprocessing is involved in this process \n",
            "\n",
            " If incase if u need to preprocess your data then for the upcoming filed type 0\n",
            "enter test size for computation of accuracy of all the possible ml algorithms.25\n",
            "\n",
            " Generating train & test datasets for the given data..\n",
            "\n",
            " Completed the genration of train and test datasets for the given data\n",
            "REGRESSION ALGORITHM ACCURACY TEST!\n",
            "\n",
            "Loading all the possible Regression models \n",
            "\n",
            "Loading completed.. \n",
            "\n",
            "Testing Accuracy for all the possible Regression models\n",
            "\n",
            " please fill the details with care when prompted to avoid errors\n",
            "[====================] 100%Enter Degree of Polyniomial for Polynomial Regression3\n",
            "\n",
            "........Loading.........\n",
            "\n",
            " This might take some couple of minutes due to bulk nature of the algorithm\n",
            "\n",
            " Kindly do bear\n",
            "\n",
            ".........LOADING.......\n",
            "Enter number of trees for random forest regression3\n",
            "\n",
            "Accuracy results are in !.\n",
            "\n",
            "Generating Dataframe for the same..\n",
            "[====================] 100%\n",
            "Note: For any 2 columns it should assumed that the Linear Regression would be a Simple Linear Regression which means that for multiple columns the Linear Regression would be a multiple Linear Regression\n",
            "\n",
            " Note: Incase if the Error , deviance values are high please use data preprocessing tools to scale down the value of the feature and try to run the algorithm again\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type of Regression</th>\n",
              "      <th>R2_score</th>\n",
              "      <th>Variance_score</th>\n",
              "      <th>Max_Error</th>\n",
              "      <th>Mean Absolute Error</th>\n",
              "      <th>Mean Squared Error</th>\n",
              "      <th>Median Absolute Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>73.090240</td>\n",
              "      <td>75.315507</td>\n",
              "      <td>0.041250</td>\n",
              "      <td>0.015185</td>\n",
              "      <td>0.000377</td>\n",
              "      <td>0.009399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Polynomial Regression</td>\n",
              "      <td>6461.295914</td>\n",
              "      <td>5634.871085</td>\n",
              "      <td>1.040608</td>\n",
              "      <td>0.116719</td>\n",
              "      <td>0.092038</td>\n",
              "      <td>0.031789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support Vector Regression(kernel=\"linear\")</td>\n",
              "      <td>7.010570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Support Vector Regression(kernel=\"poly\")</td>\n",
              "      <td>7.010570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Support Vector Regression(kernel=\"rbf\")</td>\n",
              "      <td>7.010570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Support Vector Regression(kernel=\"sigmoid\")</td>\n",
              "      <td>7.010570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070500</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Decision Tree Regression</td>\n",
              "      <td>37.194485</td>\n",
              "      <td>47.460086</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.022333</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Random Forest regression</td>\n",
              "      <td>17.744499</td>\n",
              "      <td>24.406050</td>\n",
              "      <td>0.077667</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>0.005667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Type of Regression  ...  Median Absolute Error\n",
              "0                            Linear Regression  ...               0.009399\n",
              "1                        Polynomial Regression  ...               0.031789\n",
              "2   Support Vector Regression(kernel=\"linear\")  ...               0.034000\n",
              "3     Support Vector Regression(kernel=\"poly\")  ...               0.034000\n",
              "4      Support Vector Regression(kernel=\"rbf\")  ...               0.034000\n",
              "5  Support Vector Regression(kernel=\"sigmoid\")  ...               0.034000\n",
              "6                     Decision Tree Regression  ...               0.014500\n",
              "7                     Random Forest regression  ...               0.005667\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZBIH622UMB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxFFb6JX2oqR",
        "outputId": "332a7ba6-2dac-4af8-c20b-668ca1b4c244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.196 0.063 0.026 0.01  0.031]\n",
            " [0.158 0.038 0.013 0.003 0.068]\n",
            " [0.209 0.057 0.03  0.017 0.058]\n",
            " [0.204 0.053 0.017 0.013 0.07 ]\n",
            " [0.207 0.042 0.009 0.066 0.211]\n",
            " [0.1   0.037 0.003 0.004 0.138]\n",
            " [0.161 0.044 0.011 0.07  0.076]\n",
            " [0.206 0.054 0.027 0.01  0.048]\n",
            " [0.189 0.058 0.014 0.011 0.032]\n",
            " [0.147 0.047 0.012 0.009 0.111]\n",
            " [0.064 0.044 0.007 0.002 0.205]\n",
            " [0.096 0.044 0.003 0.022 0.151]\n",
            " [0.193 0.063 0.02  0.037 0.081]\n",
            " [0.16  0.049 0.007 0.038 0.101]\n",
            " [0.155 0.051 0.02  0.012 0.04 ]\n",
            " [0.259 0.06  0.016 0.085 0.158]\n",
            " [0.11  0.025 0.006 0.    0.061]\n",
            " [0.106 0.036 0.008 0.012 0.095]\n",
            " [0.154 0.045 0.008 0.    0.252]\n",
            " [0.1   0.037 0.003 0.004 0.138]\n",
            " [0.117 0.03  0.006 0.003 0.145]\n",
            " [0.131 0.049 0.012 0.021 0.13 ]\n",
            " [0.125 0.039 0.013 0.002 0.062]\n",
            " [0.119 0.04  0.008 0.049 0.233]\n",
            " [0.144 0.049 0.012 0.013 0.086]\n",
            " [0.149 0.05  0.012 0.05  0.06 ]\n",
            " [0.186 0.047 0.018 0.05  0.007]\n",
            " [0.141 0.058 0.01  0.011 0.07 ]\n",
            " [0.094 0.041 0.005 0.014 0.124]\n",
            " [0.174 0.05  0.008 0.061 0.112]\n",
            " [0.135 0.041 0.009 0.005 0.065]\n",
            " [0.17  0.026 0.011 0.002 0.   ]\n",
            " [0.197 0.052 0.008 0.054 0.095]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-2M0Ogo2sGa",
        "outputId": "c41cee7a-a538-4fc2-954d-346465996d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.189 0.043 0.001 0.03  0.032]\n",
            " [0.141 0.045 0.021 0.013 0.074]\n",
            " [0.141 0.041 0.007 0.051 0.264]\n",
            " [0.197 0.052 0.008 0.054 0.095]\n",
            " [0.133 0.037 0.003 0.043 0.135]\n",
            " [0.082 0.061 0.002 0.012 0.147]\n",
            " [0.193 0.066 0.021 0.037 0.083]\n",
            " [0.163 0.068 0.016 0.022 0.092]\n",
            " [0.087 0.038 0.006 0.015 0.142]\n",
            " [0.158 0.034 0.019 0.005 0.014]\n",
            " [0.15  0.053 0.005 0.039 0.115]\n",
            " [0.1   0.029 0.007 0.011 0.188]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfeRyFzN2yTL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liXZF93J2uQ_",
        "outputId": "de196bda-8e20-45e4-f15d-04b1c8cb0294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.367 0.308 0.317 0.32  0.298 0.214 0.29  0.325 0.329 0.269 0.188 0.245\n",
            " 0.318 0.297 0.34  0.342 0.244 0.248 0.207 0.214 0.228 0.284 0.276 0.252\n",
            " 0.283 0.31  0.296 0.3   0.254 0.305 0.307 0.27  0.304]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28IygUAd2wK2",
        "outputId": "48cbb39f-47d5-417e-cbc7-e6d87e6c0c39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.328 0.281 0.243 0.304 0.248 0.218 0.358 0.301 0.221 0.294 0.277 0.199]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyHJ9waM2zNz",
        "outputId": "3410519a-3c2e-44ca-ccca-6c7a7fb16af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "LR = LinearRegression()\n",
        "LR.fit(x_train,y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlzpnylE3F6K",
        "outputId": "3ad030b7-e3c0-4eba-acfd-cf8d53ae93ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = LR.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3077186  0.2873395  0.2302888  0.3145529  0.25537119 0.25702254\n",
            " 0.33722868 0.32015172 0.23255249 0.2926671  0.28817311 0.21106226]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAK0XLqD3RGW",
        "outputId": "12668b16-16c1-4486-981b-e90b86dfd078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "print(LR.coef_)\n",
        "print(LR.intercept_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.31 0.33]\n",
            " [0.29 0.28]\n",
            " [0.23 0.24]\n",
            " [0.31 0.3 ]\n",
            " [0.26 0.25]\n",
            " [0.26 0.22]\n",
            " [0.34 0.36]\n",
            " [0.32 0.3 ]\n",
            " [0.23 0.22]\n",
            " [0.29 0.29]\n",
            " [0.29 0.28]\n",
            " [0.21 0.2 ]]\n",
            "[ 0.34  1.33  0.52  0.28 -0.29]\n",
            "0.1861640140148298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkfPsmv3lVM",
        "outputId": "0f4a03ed-51af-48c5-8029-bfdc7875be9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "a=r2_score(y_test, y_pred)\n",
        "print(abs(a*100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86.11443494487231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpA6VxLS3p6s",
        "outputId": "e3529d87-75be-4293-8023-91608451302b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(LR.predict([[0.05,0.01,0.1,0.07,0.09]]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.26]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}